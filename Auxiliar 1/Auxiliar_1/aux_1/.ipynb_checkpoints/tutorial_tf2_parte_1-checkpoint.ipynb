{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial tensorflow (parte 1)\n",
    "## Diseñado para la versión 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow y Numpy son los mejores amigos <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.linspace(0, 1, 15).reshape(3, 5)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.multiply(2.0, np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En muchas maneras TF2 actúa como Numpy en esteroides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyamos un modelo paramétrico, es decir, algo que toma una entrada, arroja una salida y tiene parámetros que persisten en el tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(Model):\n",
    "    def __init__(self, m=1, n=0):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.m = tf.Variable(m, dtype=tf.float32)\n",
    "        self.n = tf.Variable(n, dtype=tf.float32)\n",
    "        self.parameters = [self.m, self.n]\n",
    "        \n",
    "    def call(self, x):\n",
    "        y = tf.cast(x, dtype=tf.float32)*self.m + self.n\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linear_model = LinearModel(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linear_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 1000, dtype=np.float32)\n",
    "y = my_linear_model(x)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(x, y)\n",
    "plt.title('Salida del modelo con parámetros iniciales')\n",
    "plt.gcf().patch.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La mayoría de los algoritmos en machine learning hoy por hoy consisten en ajustar los parámetros de un modelo para minimizar una función de error.\n",
    "\n",
    "## Si puedes derivar el error con respecto a los parámetros del modelo (i.e. calcular el gradiente del error), basta usar un algoritmo de optimización de primer orden y listo! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Grafo_1](grafo_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Grafo_2](grafo_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mse_error(prediction, target):\n",
    "    return tf.reduce_mean((prediction - target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(xs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = my_linear_model(xs)\n",
    "        error = mse_error(predictions, targets)\n",
    "    gradients = tape.gradient(error, my_linear_model.parameters)\n",
    "    print(gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, my_linear_model.parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necesitamos un conjunto de entrenamiento para que el modelo aprenda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.linspace(-10, 10, 100, dtype=np.float32)\n",
    "true_m = 4.0\n",
    "true_n = -3.0\n",
    "train_y = train_x * true_m + true_n + np.random.randn(100)*4\n",
    "train_y = train_y.astype(np.float32)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(train_x, train_y)\n",
    "plt.title('training set for linear model')\n",
    "plt.gcf().patch.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A entrenar el modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_log = []\n",
    "error_log = []\n",
    "for epoch in range(100):\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch', epoch)\n",
    "    train_step(train_x, train_y)\n",
    "    train_error = mse_error(my_linear_model(train_x), train_y)\n",
    "    iteration_log.append(epoch)\n",
    "    error_log.append(train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = np.linspace(-10, 10, 1000)\n",
    "model_output = my_linear_model(x_grid)\n",
    "underlying_model = x_grid*true_m + true_n\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(x_grid, underlying_model, label='Modelo subyacente')\n",
    "plt.plot(x_grid, model_output, label='Modelo entrenado')\n",
    "plt.title('¿Qué tan bueno es el modelo resultante?')\n",
    "plt.legend()\n",
    "plt.gcf().patch.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(iteration_log, error_log)\n",
    "plt.xlabel('Épocas o iteraciones')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Curva de aprendizaje @ conjunto de entrenamiento')\n",
    "plt.gcf().patch.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué cosas hicimos hoy con tensorflow?\n",
    "* Evaluar expresiones matemáticas.\n",
    "* Crear un modelo personalizado heredando desde tf.keras.Model\n",
    "* Evaluar un modelo.\n",
    "* Crear una función de costo personalizada con @tf.function\n",
    "* Usar un optimizador.\n",
    "* Crear un *train step* usando tf.GradientTape para calcular gradientes.\n",
    "* Aplicar un ciclo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
